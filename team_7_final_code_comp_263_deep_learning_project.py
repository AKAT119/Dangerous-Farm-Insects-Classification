# -*- coding: utf-8 -*-
"""Team_7_Final_Code_COMP 263_Deep_Learning_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uv0YkQrQTGns7vlc7HkSQhaqUr3CQ9FP
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import os
import pathlib
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Dense, MaxPooling2D, Flatten, Conv2D, Dropout, BatchNormalization
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras import regularizers
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.layers import Concatenate, Embedding, Activation, multiply, Reshape
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers, models
from tensorflow.keras import regularizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img

"""---



---

#Data Pre-processing
"""

# Define the base path for the dataset
DATA_PATH = '/content/drive/MyDrive/CENTENNIAL /4th Semester Centennial/Deep Learning COMP_263_003/Project/farm_insects'

def create_dataframe(data_path):
    """Create a dataframe listing file paths and labels for images."""
    filepaths = []
    labels = []
    # List directories in data path
    directories = os.listdir(data_path)
    for directory in directories:
        dir_path = os.path.join(data_path, directory)
        if pathlib.Path(dir_path).is_dir():
            files = os.listdir(dir_path)
            for file in files:
                filepath = os.path.join(dir_path, file)
                filepaths.append(filepath)
                labels.append(directory)
    return pd.DataFrame({'filepaths': filepaths, 'labels': labels})

def encode_labels(df):
    """Convert categorical labels to numeric labels."""
    label_mapping = {label: idx for idx, label in enumerate(df['labels'].unique())}
    df['labels'] = df['labels'].map(label_mapping)
    return df, label_mapping


def split_data(df, test_size=0.15, val_size=0.15):
    """Split data into training, validation, and test sets."""
    train_val, test = train_test_split(df, test_size=test_size, random_state=42, stratify=df['labels'])
    val_size_adjusted = val_size / (1 - test_size)
    train, val = train_test_split(train_val, test_size=val_size_adjusted, random_state=42, stratify=train_val['labels'])
    return train, val, test

def plot_images(df, label_mapping, images_per_row=5):
    inv_label_mapping = {v: k for k, v in label_mapping.items()}
    unique_labels = df.groupby('labels').first().reset_index()
    num_rows = (len(unique_labels) + images_per_row - 1) // images_per_row
    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 2 * num_rows))
    axes = axes.flatten()
    for ax, (_, row) in zip(axes, unique_labels.iterrows()):
        img = load_img(row['filepaths'])
        ax.imshow(img)
        ax.axis('off')
        original_label = inv_label_mapping[row['labels']]
        ax.set_title(f"{original_label} ({row['labels']})")

    # Turn off any unused axes
    for ax in axes[len(unique_labels):]:
        ax.axis('off')

    plt.tight_layout()
    plt.show()

def plot_label_distribution(df):
    plt.figure(figsize=(10, 6))
    df['labels'].value_counts().plot(kind='bar')
    plt.xlabel('Labels')
    plt.ylabel('Number of Images')
    plt.title('Distribution of Labels in the Dataset')
    plt.show()

def load_image_in_rgb(filepath, target_size=(150, 150)):
    img = load_img(filepath, color_mode='rgb', target_size=target_size)
    img_array = img_to_array(img)
    img_array = img_array / 255.0  # Normalize
    return img_array

df = create_dataframe(DATA_PATH)
df, label_mapping = encode_labels(df)
inverse_label_mapping = {v: k for k, v in label_mapping.items()}

label_mapping

df.shape

print(df['labels'].value_counts())

df, label_mapping = encode_labels(df)
train_df, val_df, test_df = split_data(df)
print("Shape of train set:", train_df.shape)
print("Shape of validation set:", val_df.shape)
print("Shape of test set:", test_df.shape)

plot_label_distribution(df)

plot_images(train_df, label_mapping)

def plot_images_by_label(df, label_index, num_images=10, title=""):
    """Plot images for a specific label from the dataframe."""
    # Filter the dataframe for the specific label
    df_label = df[df['labels'] == label_index]

    # If there are fewer images than num_images, adjust num_images to the dataframe's size
    num_images = min(num_images, len(df_label))

    # Set up the plot
    fig, axes = plt.subplots(1, num_images, figsize=(20, 2))
    axes = axes.flatten()

    for i in range(num_images):
        img_path = df_label.iloc[i]['filepaths']
        img = load_img(img_path, color_mode='rgb')  # Ensures images are loaded in RGB
        img = img_to_array(img) / 255.0  # Normalize the image
        axes[i].imshow(img)
        axes[i].axis('off')

    plt.tight_layout()
    plt.suptitle(title, fontsize=16)
    plt.subplots_adjust(top=0.85)
    plt.show()

# Manually set the label index here for each dataset
train_label_index = 8  # Example label index for training data
val_label_index = 8    # Example label index for validation data
test_label_index = 8   # Example label index for test data

# Plotting 10 images from each dataset belonging to the manually set label
plot_images_by_label(train_df, train_label_index, num_images=10, title="Training Data: Label Fruit files{}".format(train_label_index))
plot_images_by_label(val_df, val_label_index, num_images=10, title="Validation Data: Label Fruit files{}".format(val_label_index))
plot_images_by_label(test_df, test_label_index, num_images=10, title="Test Data: Label Fruit files{}".format(test_label_index))

"""---



---

#STEP 1: Supervised CNN Model
"""

# Define CNN model architecture
def create_cnn_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # Regularize Dense layer
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Define input shape and number of classes
input_shape = (150, 150, 3)
num_classes = len(label_mapping)

# Create CNN model
model = create_cnn_model(input_shape, num_classes)

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# Convert input tensors to NumPy arrays
train_images = np.array([load_image_in_rgb(filepath) for filepath in train_df['filepaths']])
val_images = np.array([load_image_in_rgb(filepath) for filepath in val_df['filepaths']])
test_images = np.array([load_image_in_rgb(filepath) for filepath in test_df['filepaths']])

# Train the model
history = model.fit(x=train_images,
                    y=train_df['labels'],
                    validation_data=(val_images, val_df['labels']),
                    epochs=30,
                    batch_size=32)

# Extract image file paths and labels from the test set DataFrame
test_image_paths = test_df['filepaths'].tolist()
test_labels = test_df['labels'].tolist()

# Convert input tensors to NumPy arrays
test_images = np.array([load_image_in_rgb(filepath) for filepath in test_image_paths])

# Predict probabilities for test images
predictions = model.predict(test_images)

# Convert probabilities to class labels
predicted_labels = np.argmax(predictions, axis=1)

# Calculate accuracy manually
correct_predictions = np.sum(predicted_labels == test_labels)
total_samples = len(test_labels)
test_accuracy = correct_predictions / total_samples

# Print train, test, and validation accuracies
train_accuracy = history.history['accuracy'][-1]
val_accuracy = history.history['val_accuracy'][-1]

print(f"Train Accuracy: {train_accuracy}")
print(f"Validation Accuracy: {val_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# Setting up the subplot grid
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))  # Define the figure and subplot structure

# Plot on the first subplot
axes[0].plot(history.history['accuracy'], label='Training Accuracy')
axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].set_title('Training and Validation Accuracy')
axes[0].legend()

# Plot on the second subplot
test_accuracy_repeated = [test_accuracy] * len(history.history['val_accuracy'])
axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')
axes[1].plot(test_accuracy_repeated, label='Test Accuracy', linestyle='--')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Validation vs. Test Accuracy')
axes[1].legend()

# Show the plots
plt.tight_layout()  # Adjust the layout to make room for all subplot elements
plt.show()

from sklearn.metrics import confusion_matrix
# Calculate the confusion matrix
conf_matrix = confusion_matrix(test_labels, predicted_labels)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping, yticklabels=label_mapping)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Function to load and display an image
def load_and_display_image(image_path, ax, title):
    img = plt.imread(image_path)  # Load the image
    ax.imshow(img)
    ax.set_title(title)
    ax.axis('off')  # Hide axes

# Plotting predictions vs actual labels for 10 images
fig, axes = plt.subplots(2, 5, figsize=(20, 8))  # 2 rows, 5 columns
axes = axes.flatten()

# Select 10 random images from the test set
indices = np.random.choice(len(test_image_paths), 10, replace=False)

for idx, ax in zip(indices, axes):
    image_path = test_image_paths[idx]
    actual_label = inverse_label_mapping[test_labels[idx]]
    predicted_label = inverse_label_mapping[predicted_labels[idx]]
    title = f"Pred: {predicted_label}\nActual: {actual_label}"
    load_and_display_image(image_path, ax, title)

plt.tight_layout()
plt.show()

"""---



---

#STEP 2: Unsupervised Learning
"""

def load_image_and_label_for_GAN(filepath, label, target_size=(32, 32)):
    """Load and resize an image file in RGB mode and return the label."""
    img = load_img(filepath, color_mode='rgb', target_size=target_size)
    img_array = img_to_array(img)
    img_array /= 255.0  # Normalize to [0, 1]
    return img_array, label

# Assume train_df['labels'] contains the labels
train_data_GAN = [(load_image_and_label_for_GAN(row['filepaths'], row['labels'])) for index, row in train_df.iterrows()]
train_images_GAN, train_labels_GAN = zip(*train_data_GAN)
train_images_GAN = np.array(train_images_GAN)
train_labels_GAN = np.array(train_labels_GAN).reshape(-1, 1)  #

train_labels_GAN.shape

train_images_GAN.shape

train_dataset = tf.data.Dataset.from_tensor_slices((train_images_GAN, train_labels_GAN))
train_dataset = train_dataset.shuffle(buffer_size=3000).batch(256)

z_dim =10
img_size_GAN = (32,32,3)
num_classes

def generator_model():
    model = Sequential()
    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(z_dim,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((8, 8, 256)))
    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))

    z = Input(shape= (z_dim,))
    label = Input(shape=(1,), dtype = 'int32')

    label_embedding = Embedding(num_classes, z_dim, input_length = 1)(label)
    label_embedding = Flatten()(label_embedding)
    joined = multiply([z, label_embedding])
    img = model(joined)
    return Model([z, label], img)

generator = generator_model()
generator.summary()

def discriminator_model():
    model = models.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(32,32,6)))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))
    img = Input(shape= (img_size_GAN))
    label = Input(shape= (1,), dtype = 'int32')

    label_embedding = Embedding(input_dim = num_classes, output_dim = np.prod(img_size_GAN), input_length = 1)(label)
    label_embedding = Flatten()(label_embedding)
    label_embedding = Reshape(img_size_GAN)(label_embedding)

    concat = Concatenate(axis = -1)([img, label_embedding])
    prediction = model(concat)

    return Model([img, label], prediction)

# Define the loss functions and optimizers
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4, 0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, 0.5)

discriminator = discriminator_model()
discriminator.compile (loss='binary_crossentropy', optimizer=discriminator_optimizer, metrics=['accuracy'])
discriminator.summary()

z = Input(shape=(z_dim,))
label = Input(shape= (1,))
img = generator([z,label])

# discriminator.trainable = False
prediction = discriminator([img, label])

gan = Model([z, label], prediction)
gan.compile(loss= 'binary_crossentropy', optimizer = generator_optimizer)

gan.summary()

def training_step(images, labels):
    # Generate random noise and associate it with labels
    batch_size = tf.shape(images)[0]  # Get dynamic batch size from input
    noise = tf.random.normal([batch_size, z_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator([noise, labels], training=True)

        real_output = discriminator([images, labels], training=True)
        fake_output = discriminator([generated_images, labels], training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss, generated_images

num_epochs = 100
rows, cols = 4, 8

for epoch in range(num_epochs):
    for image_batch, label_batch in train_dataset:
        gen_loss, disc_loss, generated_images = training_step(image_batch, label_batch)

    print("Epoch {}: G_Loss: {:.4f}, D_Loss: {:.4f}".format(epoch + 1, gen_loss, disc_loss))
    # Optionally visualize the generated images
    # Visualizing the generated images
    fig, axs = plt.subplots(rows, cols, figsize=(10, 10))
    idx = 0
    for i in range(rows):
        for j in range(cols):
            if idx < len(generated_images):
                axs[i, j].imshow(generated_images[idx])
                axs[i, j].axis('off')
                idx += 1
            else:
                break

    plt.show()
    plt.close()

class_names =list(label_mapping.keys())
class_names

from random import randint
fig, axs = plt.subplots(4, 4, figsize=(11, 11))

for x in range(4):
    for y in range(4):
        i = randint(0, len(train_images_GAN))

        axs[x][y].imshow(train_images_GAN[i])

        axs[x][y].set_xticks([])
        axs[x][y].set_yticks([])
        class_index = int(train_labels_GAN[i])
        axs[x][y].set_xlabel(class_names[class_index])

plt.tight_layout()  # Adjust layout to prevent overlap
plt.show()

from tensorflow.image import resize

# Resize original images to match the GAN-generated images
train_images_resized = resize(train_images, [32, 32]).numpy()
val_images_resized = resize(val_images, [32, 32]).numpy()
train_labels_GAN = np.squeeze(train_labels_GAN)

# Concatenate real images with GAN-generated images along the first axis (0 axis).
combined_train_images = np.concatenate((train_images_resized, train_images_GAN), axis=0)

# Concatenate real labels with GAN-generated labels.
combined_train_labels = np.concatenate((train_df['labels'], train_labels_GAN), axis=0)

# Shuffle the combined dataset.
from sklearn.utils import shuffle
combined_train_images, combined_train_labels = shuffle(combined_train_images, combined_train_labels)

# Define CNN model architecture
def create_cnn_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)),
        MaxPooling2D((2, 2)),
        Dropout(0.2),

        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.2),

        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.2),

        Flatten(),
        Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # Regularize Dense layer
        Dropout(0.5),
        Dense(15, activation='softmax')
    ])
    return model


# Create CNN model
model = create_cnn_model()

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x=combined_train_images,
          y=combined_train_labels,
          validation_data=(val_images_resized, val_df['labels']),
          epochs=30,
          batch_size=32)

# Print validation accuracy
print(f"Validation Accuracy: {history.history['val_accuracy'][-1]}")

# Extract image file paths and labels from the test set DataFrame
test_image_paths = test_df['filepaths'].tolist()
test_labels = test_df['labels'].tolist()

# Convert input tensors to NumPy arrays
test_images = np.array([load_image_in_rgb(filepath) for filepath in test_image_paths])

test_images_resized = resize(test_images, [32, 32]).numpy()
# Predict probabilities for test images
predictions = model.predict(test_images_resized)

# Convert probabilities to class labels
predicted_labels = np.argmax(predictions, axis=1)

# Calculate accuracy manually
correct_predictions = np.sum(predicted_labels == test_labels)
total_samples = len(test_labels)
test_accuracy = correct_predictions / total_samples

# Print train, test, and validation accuracies
train_accuracy = history.history['accuracy'][-1]
val_accuracy = history.history['val_accuracy'][-1]
print(f"Train Accuracy: {train_accuracy}")
print(f"Validation Accuracy: {val_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# Set up a figure with two subplots side by side
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns

# Training vs. Validation Accuracy
ax1.plot(history.history['accuracy'], label='Training Accuracy')
ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
ax1.set_title('Training and Validation Accuracy')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend()

# Validation vs. Test Accuracy
ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')
ax2.axhline(y=test_accuracy, color='red', linestyle='--', label='Test Accuracy')
ax2.set_title('Validation and Test Accuracy')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy')
ax2.legend()

# Adjust layout
plt.tight_layout()

# Display the plots
plt.show()

# Calculate the confusion matrix
conf_matrix = confusion_matrix(test_labels, predicted_labels)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping, yticklabels=label_mapping)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

def load_and_display_image(image_path, ax, predicted_index, actual_index):
    img = plt.imread(image_path)  # Load the image
    predicted_label = inverse_label_mapping[predicted_index]
    actual_label = inverse_label_mapping[actual_index]
    title = f'Predicted: {predicted_label}\nActual: {actual_label}'
    ax.imshow(img)
    ax.set_title(title)
    ax.axis('off')  # Hide the axes

# Randomly select 10 images from the test dataset
random_indices = np.random.choice(len(test_image_paths), 10, replace=False)

# Create a figure with 2 rows and 5 columns
fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(25, 10))

for ax, idx in zip(axes.flatten(), random_indices):
    image_path = test_image_paths[idx]
    predicted_label_index = predicted_labels[idx]
    actual_label_index = test_labels[idx]
    load_and_display_image(image_path, ax, predicted_label_index, actual_label_index)

plt.tight_layout()
plt.show()

"""---



---

##STEP 3: Transfer learnig InceptionResNetV2
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

def prepare_images(filepaths, labels, target_size=(299, 299)):
    images = np.array([load_image_in_rgb(fp, target_size=target_size) for fp in filepaths])
    images = preprocess_input(images)  # Preprocess
    labels = np.array(labels)
    return images, labels

def create_inceptionresnetv2_transfer(num_classes, input_shape=(299, 299, 3)):
    base_model = InceptionResNetV2(input_shape=input_shape, include_top=False, weights='imagenet')
    base_model.trainable = False  # Freeze the convolutional base
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def create_inceptionresnetv2_from_scratch(num_classes, input_shape=(299, 299, 3)):
    base_model = InceptionResNetV2(input_shape=input_shape, include_top=False, weights=None)
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Adjust target size to (299, 299) for InceptionResNetV2
train_images, train_labels = prepare_images(train_df['filepaths'], train_df['labels'], target_size=(299, 299))
val_images, val_labels = prepare_images(val_df['filepaths'], val_df['labels'], target_size=(299, 299))
test_images, test_labels = prepare_images(test_df['filepaths'], test_df['labels'], target_size=(299, 299))

# Create models
model_transfer = create_inceptionresnetv2_transfer(len(label_mapping))
model_scratch = create_inceptionresnetv2_from_scratch(len(label_mapping))

# Train the transfer learning model
history_transfer = model_transfer.fit(
    train_images, train_labels,
    epochs=30,
    validation_data=(val_images, val_labels),
    batch_size=32
)

# Train the model from scratch
history_scratch = model_scratch.fit(
    train_images, train_labels,
    epochs=30,
    validation_data=(val_images, val_labels),
    batch_size=32
)

# Step 5: Evaluate Both Models and Plot Accuracies
# Evaluate the transfer learning model
transfer_val_accuracy = model_transfer.evaluate(test_images, test_labels)[1]

# Evaluate the from-scratch model
scratch_val_accuracy = model_scratch.evaluate(test_images, test_labels)[1]

# Calculate test accuracy for both models
test_accuracy_transfer = np.mean(np.argmax(model_transfer.predict(test_images), axis=1) == test_labels)
test_accuracy_scratch = np.mean(np.argmax(model_scratch.predict(test_images), axis=1) == test_labels)

# Assuming you have these variables defined from the model training history and evaluations
train_accuracy_transfer = history_transfer.history['accuracy'][-1]
val_accuracy_transfer = history_transfer.history['val_accuracy'][-1]
train_accuracy_scratch = history_scratch.history['accuracy'][-1]
val_accuracy_scratch = history_scratch.history['val_accuracy'][-1]

print("\nFrom Scratch Model Accuracies:")
print(f"Training Accuracy: {train_accuracy_scratch:.2f}")
print(f"Validation Accuracy: {val_accuracy_scratch:.2f}")
print(f"Test Accuracy: {test_accuracy_scratch:.2f}")
print("-------------------------------------------------")
print("Transfer Learning Model Accuracies:")
print(f"Training Accuracy: {train_accuracy_transfer:.2f}")
print(f"Validation Accuracy: {val_accuracy_transfer:.2f}")
print(f"Test Accuracy: {test_accuracy_transfer:.2f}")

# Plotting training, validation, and test accuracy for both models
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Transfer Learning Model Accuracies
axes[0].plot(history_transfer.history['accuracy'], label='Training Accuracy (Transfer)')
axes[0].plot(history_transfer.history['val_accuracy'], label='Validation Accuracy (Transfer)')
axes[0].axhline(y=test_accuracy_transfer, color='r', linestyle='--', label='Test Accuracy (Transfer)')
axes[0].set_title('Transfer Learning Model Accuracy')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend()

# From Scratch Model Accuracies
axes[1].plot(history_scratch.history['accuracy'], label='Training Accuracy (Scratch)')
axes[1].plot(history_scratch.history['val_accuracy'], label='Validation Accuracy (Scratch)')
axes[1].axhline(y=test_accuracy_scratch, color='r', linestyle='--', label='Test Accuracy (Scratch)')
axes[1].set_title('From Scratch Model Accuracy')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].legend()

plt.tight_layout()
plt.show()

# Confusion matrices for both models
# Predictions for transfer learning model
predicted_labels_transfer = np.argmax(model_transfer.predict(test_images), axis=1)
cm_transfer = confusion_matrix(test_labels, predicted_labels_transfer)

# Predictions for from scratch model
predicted_labels_scratch = np.argmax(model_scratch.predict(test_images), axis=1)
cm_scratch = confusion_matrix(test_labels, predicted_labels_scratch)

# Plotting the confusion matrix for the transfer learning model
plt.figure(figsize=(10, 8))
sns.heatmap(cm_transfer, annot=True, fmt="d", cmap='Blues', xticklabels=inverse_label_mapping.values(), yticklabels=inverse_label_mapping.values())
plt.title('Confusion Matrix for Transfer Learning Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Plotting the confusion matrix for the from scratch model
plt.figure(figsize=(10, 8))
sns.heatmap(cm_scratch, annot=True, fmt="d", cmap='Blues', xticklabels=inverse_label_mapping.values(), yticklabels=inverse_label_mapping.values())
plt.title('Confusion Matrix for From Scratch Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Define label mapping
label_mapping = {
    'Spider Mites': 0,
    'Aphids': 1,
    'Africanized Honey Bees (Killer Bees)': 2,
    'Corn Earworms': 3,
    'Western Corn Rootworms': 4,
    'Armyworms': 5,
    'Tomato Hornworms': 6,
    'Citrus Canker': 7,
    'Fruit Flies': 8,
    'Cabbage Loopers': 9,
    'Colorado Potato Beetles': 10,
    'Corn Borers': 11,
    'Fall Armyworms': 12,
    'Brown Marmorated Stink Bugs': 13,
    'Thrips': 14
}

# Invert the label mapping to use for plotting
inverse_label_mapping = {v: k for k, v in label_mapping.items()}

# Make predictions with both models
predictions_transfer = model_transfer.predict(test_images)
predicted_labels_transfer = np.argmax(predictions_transfer, axis=1)

predictions_scratch = model_scratch.predict(test_images)
predicted_labels_scratch = np.argmax(predictions_scratch, axis=1)

# Function to plot images with actual and predicted labels
def plot_predictions(images, actuals, preds_transfer, preds_scratch, title, rows=2, cols=5):
    fig, axes = plt.subplots(rows, cols, figsize=(15, 6))
    axes = axes.flatten()
    for i, ax in enumerate(axes):
        if i >= len(images):
            ax.axis('off')  # Hide unused subplots
            continue
        # Normalize and plot image
        img = images[i].astype('float32') / 255.0 if images[i].max() > 1 else images[i]
        ax.imshow(img)
        # Use inverse_label_mapping to map numerical labels back to string labels
        ax.set_title(f"True: {inverse_label_mapping.get(actuals[i], 'Unknown')}\nTrans: {inverse_label_mapping.get(preds_transfer[i], 'Unknown')}\nScratch: {inverse_label_mapping.get(preds_scratch[i], 'Unknown')}")
        ax.axis('off')
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

# Select 10 random indices from the test dataset
sample_indices = np.random.choice(test_images.shape[0], 10, replace=False)

sample_images = test_images[sample_indices]
sample_actual_labels = test_labels[sample_indices]
sample_labels_transfer = predicted_labels_transfer[sample_indices]
sample_labels_scratch = predicted_labels_scratch[sample_indices]

# Plotting the images with predictions from both models
plot_predictions(
    sample_images,
    sample_actual_labels,
    sample_labels_transfer,
    sample_labels_scratch,
    "Model Predictions Comparison"
)

"""---



---

# Model Comparision
"""

import matplotlib.pyplot as plt

# Accuracies for each model type
train_accuracies = [0.7088, 0.8876, 0.76, 0.99]
test_accuracies = [0.3138, 0.4267, 0.31, 0.79]

# Define the labels and colors for the bar chart
model_labels = ['Base CNN', 'CNN with GAN', 'InceptionResNetV2 Scratch', 'InceptionResNetV2 Transfer']
colors = ['blue', 'green', 'orange', 'red']

# Create subplots for train, validation, and test accuracy comparisons
fig, axes = plt.subplots(1, 2, figsize=(20, 8))

# Bar chart for Training Accuracy
axes[0].bar(model_labels, train_accuracies, color=colors)
axes[0].set_title('Training Accuracy Comparison')
axes[0].set_ylabel('Accuracy')
axes[0].set_xticklabels(model_labels, rotation=45, ha='right')
axes[0].set_ylim(0, 1.1)

# Bar chart for Test Accuracy
axes[1].bar(model_labels, test_accuracies, color=colors)
axes[1].set_title('Test Accuracy Comparison')
axes[1].set_ylabel('Accuracy')
axes[1].set_xticklabels(model_labels, rotation=45, ha='right')
axes[1].set_ylim(0, 1.1)

# Display the plot with a tight layout
plt.tight_layout()
plt.show()